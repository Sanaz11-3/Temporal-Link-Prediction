{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4337d0e-9ace-4305-b44b-ce73c89764a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import keras\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import networkx as nx\n",
    "from time import time\n",
    "from numpy import dot\n",
    "import tensorflow as tf\n",
    "from numpy import unique\n",
    "from numpy import loadtxt\n",
    "from keras import Sequential\n",
    "from numpy.linalg import norm\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from itertools import combinations\n",
    "from tensorflow.keras import Model\n",
    "from sklearn.utils import resample\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from tensorflow.keras.layers import Lambda,Input,Conv1D,Dense,Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D,MaxPooling1D,Flatten\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score\n",
    "\n",
    "from dynamicgem.embedding.dynAERNN import DynAERNN\n",
    "from dynamicgem.evaluation import visualize_embedding as viz\n",
    "from dynamicgem.visualization import plot_dynamic_sbm_embedding\n",
    "from dynamicgem.graph_generation import dynamic_SBM_graph as sbm\n",
    "from dynamicgem.utils import graph_util, plot_util, dataprep_util\n",
    "from dynamicgem.evaluation import evaluate_graph_reconstruction as gr\n",
    "\n",
    "random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5805caf0-9738-433b-8ce3-98f1b94836fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Approach:\n",
    "    \n",
    "    def __init__(self, dim, history, lookback, ae_series_len, series_len, subgraphs, samp_id):\n",
    "        self.dim = dim\n",
    "        self.history = history\n",
    "        self.lookback = lookback\n",
    "        self.ae_series_len = ae_series_len\n",
    "        self.series_len = series_len\n",
    "        self.subgraphs = subgraphs\n",
    "#         self.sample = sample\n",
    "        self.samp_id = samp_id\n",
    "        \n",
    "#     def subgraph_extraction(self):\n",
    "#         subgraphs = []\n",
    "#         for g in self.graphs:\n",
    "#             subgraphs.append(g.subgraph(self.sample))\n",
    "#         return subgraphs\n",
    "    \n",
    "    def emb_generate(self, subgraphs):\n",
    "        embs = []\n",
    "        embedding = DynAERNN(d = self.dim,\n",
    "            beta           = 5,\n",
    "            n_prev_graphs  = self.lookback,\n",
    "            nu1            = 1e-6,\n",
    "            nu2            = 1e-6,\n",
    "            n_aeunits      = [500, 300],\n",
    "            n_lstmunits    = [500,self.dim],\n",
    "            rho            = 0.3,\n",
    "            n_iter         = 150,\n",
    "            xeta           = 1e-3,\n",
    "            n_batch        = 100,)\n",
    "        for temp_var in range(self.lookback+1, self.ae_series_len+1):\n",
    "            emb, _ = embedding.learn_embeddings(subgraphs[:temp_var])\n",
    "            embs.append(emb)\n",
    "        return embs\n",
    "    \n",
    "    def generate_x_y_index(self, graph_):\n",
    "        x = []\n",
    "        y = []\n",
    "        pos_links = list(graph_.edges)\n",
    "        num_pos_links = len(pos_links)\n",
    "        graph_complement = nx.complement(graph_)\n",
    "        graph_complement_links = list(graph_complement.edges)\n",
    "        neg_links = random.sample(graph_complement_links, num_pos_links)\n",
    "        for i in range(num_pos_links):\n",
    "            temp = list(pos_links[i])\n",
    "            temp_2 = [list(graph_.nodes).index(temp[0]),list(graph_.nodes).index(temp[1])]\n",
    "            x.append(temp_2)\n",
    "            y.append(1)\n",
    "        for i in range(num_pos_links):\n",
    "            temp = list(neg_links[i])\n",
    "            temp_2 = [list(graph_.nodes).index(temp[0]),list(graph_.nodes).index(temp[1])]\n",
    "            x.append(temp_2)\n",
    "            y.append(0)    \n",
    "        data = list(zip(x, y))\n",
    "        random.shuffle(data)\n",
    "        x, y = zip(*data)\n",
    "        return x, y\n",
    "    \n",
    "    def generate_x_y(self, loc, ind):\n",
    "        pred_locs = []\n",
    "        for i in (ind):\n",
    "            pred_locs.append([loc[i[0]],loc[i[1]]])\n",
    "        return pred_locs\n",
    "    \n",
    "    def score_(self, y, pred_sim):\n",
    "        print('AUROC-SCORE:', roc_auc_score(y, pred_sim))\n",
    "        print('AUPRC-SCORE:', average_precision_score(y, pred_sim))\n",
    "    \n",
    "    def similarity_(self, x):\n",
    "        dist = []\n",
    "        x = np.array(x)\n",
    "        for i in range(len(x)):\n",
    "            temp = np.linalg.norm(x[i][0]-x[i][1])\n",
    "            dist.append(temp)\n",
    "        max_ = max(dist)\n",
    "        min_ = min(dist)\n",
    "        dist = [(dist[i]-min_)/(max_-min_) for i in range(len(dist))]\n",
    "        sim = [1-dist[i] for i in range(len(dist))]\n",
    "#         name = 'sim_mp'+str(self.samp_id)+'_'+str(self.dim)+'_'+str(self.series_len)+'_'+str(self.history)\n",
    "#         path = '/Users/sanaz/Desktop/data/My_Approach/'+str(name)+'.npy'\n",
    "#         np.save(path, sim)\n",
    "        return sim\n",
    "    \n",
    "    def raw_baseline(self, emb, ind, y):\n",
    "        predicted_sim = self.similarity_(x)\n",
    "        print('Raw Embedding Performance With Setting: dim = ')\n",
    "        score_(y, predicted_sim)\n",
    "        \n",
    "    def vel_acc(self, data, vel_model):\n",
    "        shape_ = list(np.array(data).shape)[1]\n",
    "        vel = []\n",
    "        for i in range(len(data)-1):\n",
    "            vel.append(data[i+1]-data[i])\n",
    "        vel_reshaped = np.array(vel).reshape(shape_,len(vel),self.dim) \n",
    "    \n",
    "        train_x = []\n",
    "        train_y = []\n",
    "        temp = [[] for i in range(len(vel)-self.history)]\n",
    "        test_x = []\n",
    "\n",
    "        num_nodes = shape_\n",
    "        for i in range(num_nodes):\n",
    "            j_temp = 0\n",
    "            for j in range(len(vel)-self.history):\n",
    "                train_x.append(vel_reshaped[i][j:j+self.history])\n",
    "                train_y.append(vel_reshaped[i][j+self.history])\n",
    "                temp[j].append(vel_reshaped[i][j:j+self.history])\n",
    "                j_temp = j\n",
    "            test_x.append(vel_reshaped[i][j_temp+1: ])\n",
    "    \n",
    "        train_x, train_y, test_x = np.array(train_x), np.array(train_y), np.array(test_x)\n",
    "        temp = np.array(temp)\n",
    "        vel_model.fit(train_x, train_y, epochs = 150, verbose=0)\n",
    "    \n",
    "        pred = []\n",
    "        for i in temp:\n",
    "            i = np.array(i)\n",
    "            pred.append(vel_model.predict(i))\n",
    "        future = vel_model.predict(test_x)\n",
    "        pred.append(future)\n",
    "        return pred\n",
    "    \n",
    "    def velocity_aggregation__(self, s_graphs,vel_series):\n",
    "        num_nodes = len(list(s_graphs[0].nodes))\n",
    "        agg_vel = []\n",
    "        num = self.history\n",
    "        if self.history > len(vel_series):\n",
    "            num = len(vel_series)\n",
    "        for i in range(num_nodes):\n",
    "            temp = 0\n",
    "            for j in range(num):\n",
    "                temp = temp + (j+1)*vel_series[j][i]\n",
    "            temp = 2*temp/(num*(num+1))\n",
    "            agg_vel.append(temp)\n",
    "        return(agg_vel)\n",
    "\n",
    "    def loc_by_vel(self, loc, vel_series):\n",
    "        #vel = velocity_aggregation__(graphs,vel_series,lookback)\n",
    "        res = vel_series+loc\n",
    "        return res\n",
    "    \n",
    "    def velocity_model(self, activation_fn='relu', ret_seq=False):\n",
    "        n_units = [512,256,self.dim]\n",
    "        model = Sequential()\n",
    "        n_rnn_layers = len(n_units)\n",
    "        return_sequences = 1\n",
    "        model.add(LSTM(n_units[0],\n",
    "                   input_shape=(self.history, self.dim),\n",
    "                   return_sequences=return_sequences))\n",
    "        for l_idx, n_unit in enumerate(n_units[1:-1]):\n",
    "            model.add(LSTM(n_unit,return_sequences=True))\n",
    "        if n_rnn_layers > 1:\n",
    "            model.add(LSTM(n_units[-1],return_sequences=False))\n",
    "        xeta,n_batch = 1e-3,100\n",
    "        adam = Adam(lr=xeta, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "        model.compile(optimizer=adam, loss='mse', metrics=[\"mse\"])\n",
    "        return model\n",
    "    \n",
    "    def neighbor_aggregation(self,graph, loc):\n",
    "        nodes_nei = []\n",
    "        nodes = list(graph.nodes())\n",
    "        num_nodes = len(nodes)\n",
    "        for i in range(num_nodes):\n",
    "            nodes_nei.append(list(graph.neighbors(nodes[i])))\n",
    "        nodes_nei_indices = []\n",
    "        for i in range(num_nodes):\n",
    "            if len(nodes_nei[i])>0:\n",
    "                temp = []\n",
    "                for j in nodes_nei[i]:\n",
    "                    temp.append(nodes.index(j))\n",
    "                temp.append(i)\n",
    "                nodes_nei_indices.append(temp)\n",
    "            else:\n",
    "                nodes_nei_indices.append(i)\n",
    "        new_loc = []\n",
    "        for i in range(num_nodes):\n",
    "            if type(nodes_nei_indices[i]) == list:\n",
    "                temp = [0 for k in range(self.dim)]\n",
    "                for j in nodes_nei_indices[i]:\n",
    "                    temp = temp + loc[j]\n",
    "                temp = temp/(len(nodes_nei_indices[i])+1)\n",
    "                new_loc.append(temp)\n",
    "            else:\n",
    "                new_loc.append(loc[nodes_nei_indices[i]])       \n",
    "        return new_loc\n",
    "                      \n",
    "    def my_main(self):\n",
    "        subgraphs = self.subgraphs\n",
    "        test_subgraph = subgraphs[-1]\n",
    "        subgraphs = subgraphs[:-1]\n",
    "        embs = self.emb_generate(subgraphs)\n",
    "        #embs = self.emb_generate(subgraphs)\n",
    "        #name = 'emb_'+str(self.samp_id)+'_'+str(self.dim)+'_'+str(self.series_len)+'_'+str(self.history)\n",
    "        #path_embs = str(name)+'.npy'\n",
    "        #np.save(path_embs, embs)\n",
    "        #path_ae = 'ae_probabilities'+str(self.samp_id)+'_'+str(self.dim)+'_'+str(self.series_len)+'_'+str(self.history)+'.npy'\n",
    "        #np.save(path_ae, ae_pred)\n",
    "        ind, y = self.generate_x_y_index(test_subgraph)\n",
    "        \n",
    "        model = self.velocity_model(activation_fn='relu', ret_seq=False)\n",
    "        velocity = self.vel_acc(embs, model)\n",
    "        agg_vel = self.velocity_aggregation__(subgraphs,velocity)\n",
    "        locPvel = self.loc_by_vel(embs[-1], agg_vel)\n",
    "        final_loc = self.neighbor_aggregation(subgraphs[-1], locPvel)\n",
    "        pred_locs = self.generate_x_y(final_loc, ind)\n",
    "        sim = self.similarity_(pred_locs)\n",
    "        self.score_(y, sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f816b7-6d7e-492e-b9a8-2167835f3d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
